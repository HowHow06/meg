# meg (fork)

This repo is a fork to [meg](https://github.com/tomnomnom/meg) by Tom Hudson.
meg is a tool for fetching lots of URLs but still being 'nice' to servers.

It can be used to fetch many paths for many hosts; fetching one path
for all hosts before moving on to the next path and repeating.

You get lots of results quickly, but non of the individual hosts get
flooded with traffic.

## About this fork

This fork of introduces several enhanced features to improve functionality and usability:

1. **Retry Mechanism**: Added support for retrying failed requests, default to 3 max retries, configurable via the `-m` or `--maxretries` argument. Users can specify the number of retries for failed requests, with a default 2-second delay between each retry.
2. **Custom User-Agent**: Added the ability to specify a custom User-Agent string using the `-u` or `--useragent` argument, allowing for greater flexibility in request customization.
3. **Error Logging**: All failed requests are now logged into a dedicated `error` file within the output directory, making it easier to debug and analyze failed requests.

These extensions make the tool more robust and adaptable to different use cases, improving the user experience while maintaining compatibility with the original functionality.

## Install

### Install by Building the Project Locally

1. **Clone the Repository**:  
   Clone this forked repository to your local machine:

   ```bash
   git clone https://github.com/HowHow06/meg.git
   cd meg
   ```

2. **Build the Binary**:  
   Build the `meg` binary using the Go toolchain:

   ```bash
   go build -o meg
   ```

3. **Run the Tool**:  
   You can now use the `meg` binary directly:
   ```bash
   ./meg -h
   ```

Ensure you have [Go](https://golang.org/doc/install) installed and configured on your system before proceeding.

### Install by Directly Installing with Go

If you have Go 1.9 or later installed and configured you can install meg with `go install`:

```
▶ go install github.com/howhow06/meg@latest
```

## Basic Usage

Given a file full of paths:

```
/robots.txt
/.well-known/security.txt
/package.json
```

And a file full of hosts (with a protocol):

```
http://example.com
https://example.com
http://example.net
```

`meg` will request each _path_ for every _host_:

```
▶ meg --verbose paths hosts
out/example.com/45ed6f717d44385c5e9c539b0ad8dc71771780e0 http://example.com/robots.txt (404 Not Found)
out/example.com/61ac5fbb9d3dd054006ae82630b045ba730d8618 https://example.com/robots.txt (404 Not Found)
out/example.net/1432c16b671043271eab84111242b1fe2a28eb98 http://example.net/robots.txt (404 Not Found)
out/example.net/61deaa4fa10a6f601adb74519a900f1f0eca38b7 http://example.net/.well-known/security.txt (404 Not Found)
out/example.com/20bc94a296f17ce7a4e2daa2946d0dc12128b3f1 http://example.com/.well-known/security.txt (404 Not Found)
...
```

## Detailed Usage

meg's help output tries to actually be helpful:

```
▶ meg --help
Request many paths for many hosts

Usage:
  meg [path|pathsFile] [hostsFile] [outputDir]

Options:
  -b, --body <val>           Set the request body
  -c, --concurrency <val>    Set the concurrency level (default: 20)
  -u, --useragent <val>      User agent (optional)
  -d, --delay <millis>       Milliseconds between requests to the same host (default: 5000)
  -H, --header <header>      Send a custom HTTP header
  -L, --location             Follow redirects / location header
  -r, --rawhttp              Use the rawhttp library for requests (experimental)
  -s, --savestatus <status>  Save only responses with specific status code
  -t, --timeout <millis>     Set the HTTP timeout (default: 10000)
  -v, --verbose              Verbose mode
  -X, --method <method>      HTTP method (default: GET)
  -m, --maxretries <val>       Max number of retry when a request fails (default: 3)

Defaults:
  pathsFile: ./paths
  hostsFile: ./hosts
  outputDir:  ./out

  errorDir:  ./error

Paths file format:
  /robots.txt
  /package.json
  /security.txt

Hosts file format:
  http://example.com
  https://example.edu
  https://example.net

Examples:
  meg /robots.txt
  meg paths.txt hosts.txt output
```

### Custom User Agent

This fork allows you to specify a custom User-Agent string for your requests using the `-u` or `--useragent` flag. Here's how you can use it:

1. **Basic Usage**:  
   Run the tool with your desired User-Agent:

   ```bash
   ▶ meg -u "MyCustomUserAgent/1.0" paths hosts
   ```

2. **Example**:  
   If you want to mimic a browser User-Agent, you can use:

   ```bash
   ▶ meg -u "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36" paths hosts
   ```

3. **Default Behavior**:  
   If no User-Agent is specified, the tool will use its default User-Agent:
   ```
   Mozilla/5.0 (compatible; howhow06-meg/0.2)
   ```

### Concurrency

By default meg will attempt to make 20 concurrent requests. You can change that
with the `-c` or `--concurrency` option:

```
▶ meg --concurrency 5
```

It's not very friendly to keep the concurrency level higher than the number of
hosts - you may end up sending lots of requests to one host at once.

### Delay

By default meg will wait 5000 milliseconds between requests to the same host.
You can override that with the `-d` or `--delay` option:

```
▶ meg --delay 10000
```

**Warning:** before reducing the delay, ensure that you have permission to make
large volumes of requests to the hosts you're targeting.

### Adding Headers

You can set additional headers on the requests with the `-H` or `--header`
option:

```
▶ meg --header "Origin: https://evil.com"
▶ grep -h '^>' out/example.com/*
> GET /.well-known/security.txt HTTP/1.1
> Origin: https://evil.com
> Host: example.com
...
```

### Saving Only Certain Status Codes

If you only want to save results that returned a certain status code, you can
use the `-s` or `--savestatus` option:

```
▶ meg --savestatus 200 /robots.txt
```

---

## Getting Response for a Subdomain

To use the `find_response.sh` script, follow these steps:

1. **Make the Script Executable**: In your terminal, navigate to the directory where you saved the script and run:

   ```bash
   chmod +x find_response.sh
   ```

2. **Run the Script**:

   - The script requires at least one parameter (`subdomain`) and an optional second parameter (`output-directory`).
   - Run the script as follows:
     ```bash
     ./find_response.sh "http://example.com" "/path/to/output-directory"
     ```
     - Replace `"http://example.com"` with the actual subdomain you want to search.
     - Replace `"/path/to/output-directory"` with the path to the directory containing the `index` file, or leave it blank to default to `./out`.

3. **Example Usage**:

   - To search for `https://dev.example.com/` in the default `./out` directory:
     ```bash
     ./find_response.sh "https://dev.example.com/"
     ```

4. **Understanding the Output**:
   - If the subdomain is found in `<output-directory>/index`, the script will output the contents of the first matching file path.

This should execute the script and provide the content of the first match found in the `index` file.

---

## Extracting `meg` Output to TSV with the Python Script

The `extract_information_from_meg_result` Python script processes the output of the `meg` tool and converts it into a structured TSV format for easier analysis. It extracts useful headers (e.g., `Content-Type`, `Content-Length`, `Server`, `Location`) and handles errors. Here's how to use the script:

1. **Install Required Libraries**:  
   Ensure the required Python libraries are installed. The script requires `pandas`, which can be installed with:

   ```bash
   pip install pandas
   ```

2. **Prepare the Output Directory**:  
   Ensure the `meg` output files (e.g., `index`, `error`) are available in the desired directory (default: `out`).

3. **Run the Script**:  
   Use the script with the `--source_dir` argument to specify the directory containing the `meg` output files:

   ```bash
   python extract_information_from_meg_result.py --source_dir <output_directory>
   ```

   If `--source_dir` is not specified, it defaults to `out`.

4. **Generated Files**:

   - **`subdomains_with_response.tsv`**: A TSV file containing subdomains, their response status, types (`http` or `https`), and extracted headers.
   - **`subdomains_errors.tsv`**: A TSV file listing subdomains that failed, along with their corresponding error statuses.

5. **Example Command**:
   If the `meg` output is in the default `out` directory:

   ```bash
   python extract_information_from_meg_result.py
   ```

   For a custom directory:

   ```bash
   python extract_information_from_meg_result.py --source_dir custom_output
   ```

This script provides a structured view of the `meg` results, making it easier to analyze and debug web requests.
